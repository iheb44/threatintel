# docker-compose.yml
# Threat Intelligence Feed Processing Setup

services:
  # ===== INFRASTRUCTURE SERVICES =====
  
  tor:
    image: dperson/torproxy:latest
    container_name: torproxy
    restart: unless-stopped
    networks:
      - dw-net
    ports:
      - "9050:9050"
    volumes:
      - tor_data:/var/lib/tor
    healthcheck:
      test: ["CMD", "curl", "-x", "socks5://localhost:9050", "https://check.torproject.org"]
      interval: 60s
      timeout: 10s
      retries: 3

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.1
    container_name: es
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - cluster.name=threatintel-cluster
      - node.name=es-node
      - network.host=0.0.0.0
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    mem_limit: 4g
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - dw-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  elasticsearch-init:
    image: appropriate/curl:latest
    container_name: es-init
    depends_on:
      - elasticsearch
    networks:
      - dw-net
    command: >
      sh -c "
      echo 'Waiting for Elasticsearch...';
      until curl -s http://elasticsearch:9200 >/dev/null; do sleep 5; done;
      echo 'Creating IOC index template...';
      curl -X PUT http://elasticsearch:9200/_index_template/iocs_template -H 'Content-Type: application/json' -d '
      {
        \"index_patterns\": [\"iocs*\"],
        \"template\": {
          \"mappings\": {
            \"properties\": {
              \"ioc_value\": {\"type\": \"keyword\"},
              \"ioc_type\": {\"type\": \"keyword\"},
              \"source_feed\": {\"type\": \"keyword\"},
              \"feed_url\": {\"type\": \"keyword\"},
              \"timestamp\": {\"type\": \"date\"},
              \"content_hash\": {\"type\": \"keyword\"},
              \"threat_types\": {\"type\": \"keyword\"},
              \"entities\": {
                \"properties\": {
                  \"ips\": {\"type\": \"ip\"},
                  \"domains\": {\"type\": \"keyword\"},
                  \"cves\": {\"type\": \"keyword\"}
                }
              }
            }
          }
        }
      }';
      echo 'IOC template created successfully';
      "

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.1
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - MONITORING_ENABLED=true
      - TELEMETRY_ENABLED=false
    ports:
      - "5601:5601"
    networks:
      - dw-net
    depends_on:
      - elasticsearch
    volumes:
      - ./kibana/dashboards:/usr/share/kibana/data/dashboards:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5601/api/status"]
      interval: 30s
      timeout: 10s
      retries: 5

  # ===== THREAT INTELLIGENCE PROCESSING =====

  crawler-enhanced:
    build:
      context: ./crawler
      dockerfile: Dockerfile
    container_name: dw-crawler-enhanced
    restart: unless-stopped
    command: python -m crawler  # Using feed crawler for threat intelligence
    environment:
      - ELASTIC_HOST=elasticsearch
      - ELASTIC_PORT=9200
      - TOR_SOCKS=tor:9050
      - USE_TOR=${USE_TOR:-false}
      - MAX_PAGES_PER_SEED=${MAX_PAGES_PER_SEED:-5}
      - POSTGRES_DSN=postgresql://crawler:${POSTGRES_PASSWORD:-SecurePass123!}@postgres:5432/threatintel
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - ENABLE_PII_REDACTION=${ENABLE_PII_REDACTION:-false}
      - USE_PLAYWRIGHT=${USE_PLAYWRIGHT:-false}
      - ES_INDEX=iocs  # Using iocs index for threat data
      - CRAWLER_TYPE=feed  # Feed processing mode
    volumes:
      - ./crawler/config:/app/config
      - ./crawler/state:/app/state
      - crawler_logs:/app/logs
    depends_on:
      - elasticsearch
      - postgres
      - redis
    networks:
      - dw-net
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G

  celery-worker:
    build:
      context: ./crawler
      dockerfile: Dockerfile
    command: celery -A crawler_tasks worker --loglevel=info --concurrency=4 -Q feeds,monitoring
    environment:
      - ELASTIC_HOST=elasticsearch
      - ELASTIC_PORT=9200
      - POSTGRES_DSN=postgresql://crawler:${POSTGRES_PASSWORD:-SecurePass123!}@postgres:5432/threatintel
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - ES_INDEX=iocs  # Using iocs index
    volumes:
      - ./crawler:/app
      - ./crawler/config:/app/config
      - crawler_logs:/app/logs
    working_dir: /app
    depends_on:
      - redis
      - postgres
      - elasticsearch
    networks:
      - dw-net
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 1G

  celery-beat:
    build:
      context: ./crawler
      dockerfile: Dockerfile
    command: celery -A crawler_tasks beat --loglevel=info
    environment:
      - ELASTIC_HOST=elasticsearch
      - ELASTIC_PORT=9200
      - POSTGRES_DSN=postgresql://crawler:${POSTGRES_PASSWORD:-SecurePass123!}@postgres:5432/threatintel
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
    volumes:
      - ./crawler:/app
      - ./crawler/config:/app/config
      - celerybeat_schedule:/app/celerybeat-schedule
    working_dir: /app
    depends_on:
      - redis
    networks:
      - dw-net

  # ===== API & INTERFACE SERVICES =====

  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: dw-api
    ports:
      - "8000:8000"
    environment:
      - ELASTIC_HOST=elasticsearch
      - ELASTIC_PORT=9200
      - POSTGRES_DSN=postgresql://crawler:${POSTGRES_PASSWORD:-SecurePass123!}@postgres:5432/threatintel
      - REDIS_URL=redis://redis:6379/0
      - ES_INDEX=iocs  # Using iocs index for threat data
    volumes:
      - ./api/config:/app/config
    depends_on:
      - elasticsearch
      - postgres
      - redis
    networks:
      - dw-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

  elastalert:
    image: jertel/elastalert2:2.15.0
    container_name: elastalert
    restart: unless-stopped
    environment:
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - ELASTICSEARCH_USE_SSL=False
      - ES_INDEX=iocs  # Using iocs index for alerts
    volumes:
      - ./elastalert/rules:/opt/elastalert/rules
      - ./elastalert/config.yaml:/opt/elastalert/config.yaml
      - elastalert_data:/opt/elastalert/data
    depends_on:
      - elasticsearch
    networks:
      - dw-net

  # ===== MONITORING & METRICS =====

  grafana:
    image: grafana/grafana:10.0.0
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-changeme_grafana}
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/var/lib/grafana/dashboards/crawler-overview.json
    ports:
      - "3000:3000"
    networks:
      - dw-net
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - elasticsearch
      - prometheus

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - dw-net
    depends_on:
      - crawler-enhanced

  flower:
    image: mher/flower:latest
    container_name: flower
    command: celery --broker=redis://redis:6379/0 flower --port=5555
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - FLOWER_BASIC_AUTH=admin:${FLOWER_PASSWORD:-admin}
    depends_on:
      - redis
    networks:
      - dw-net

  # ===== DATABASE & QUEUE SERVICES =====

  postgres:
    image: postgres:15-alpine
    container_name: postgres
    environment:
      - POSTGRES_DB=threatintel
      - POSTGRES_USER=crawler
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-SecurePass123!}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    ports:
      - "5432:5432"
    networks:
      - dw-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U crawler -d threatintel"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: redis
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - dw-net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=crawler
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD:-SecurePass123!}
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      - dw-net
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

  # ===== NETWORK & PROXY SERVICES =====

  nginx:
    image: nginx:alpine
    container_name: nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/certs:/etc/nginx/certs:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - api
      - kibana
      - grafana
      - flower
    networks:
      - dw-net
    restart: unless-stopped

  elasticsearch-exporter:
    image: bitnami/elasticsearch-exporter:latest
    container_name: elasticsearch-exporter
    environment:
      - ES_URI=http://elasticsearch:9200
      - ES_ALL=true
      - ES_INDICES=true
      - ES_INDICES_SETTINGS=true
      - ES_SHARDS=true
      - ES_SNAPSHOTS=true
      - ES_CLUSTER_SETTINGS=true
    ports:
      - "9114:9114"
    depends_on:
      - elasticsearch
    networks:
      - dw-net 

  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    environment:
      - REDIS_ADDR=redis://redis:6379
    ports:
      - "9121:9121"
    depends_on:
      - redis
    networks:
      - dw-net

# ===== NETWORKS & VOLUMES =====

networks:
  dw-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  esdata:
    driver: local
  grafana_data:
    driver: local
  tor_data:
    driver: local
  postgres_data:
    driver: local
  redis_data:
    driver: local
  rabbitmq_data:
    driver: local
  prometheus_data:
    driver: local
  elastalert_data:
    driver: local
  crawler_logs:
    driver: local
  celerybeat_schedule:
    driver: local
  nginx_logs:
    driver: local
